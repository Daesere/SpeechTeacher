{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cfbffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "equal (reference: 0, 3) (attempt: 0, 3)\n",
      "delete (reference: 3, 4) (attempt: 3, 3)\n",
      "equal (reference: 4, 5) (attempt: 3, 4)\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2Tokenizer,Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "from phonemizer import phonemize\n",
    "import Levenshtein as lev\n",
    "import librosa\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Specific for my local implementation\n",
    "os.environ['PHONEMIZER_ESPEAK_LIBRARY'] = 'C:/Program Files/eSpeak NG/libespeak-ng.dll'\n",
    "\n",
    "class Pipeline():\n",
    "    \"\"\"\n",
    "    Evaluates speech and returns feedback to\n",
    "    target pronunciation points that require further work.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.model_name = \"facebook/wav2vec2-lv-60-espeak-cv-ft\"\n",
    "        self.feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(self.model_name)\n",
    "        self.tokenizer = Wav2Vec2Tokenizer.from_pretrained(self.model_name)\n",
    "        self.processor = Wav2Vec2Processor.from_pretrained(self.model_name, feature_extractor=self.feature_extractor, tokenizer=self.tokenizer)\n",
    "        self.model = Wav2Vec2ForCTC.from_pretrained(self.model_name)\n",
    "\n",
    "    def speech2phonemes(self, audio_path):\n",
    "        \"\"\"Transforms user audio into IPA phonemes for evaluation\"\"\"\n",
    "        # Load and normalize the user's audio\n",
    "        speech, sr = librosa.load(audio_path, sr=16_000, mono=True)\n",
    "        speech = librosa.util.normalize(speech)\n",
    "\n",
    "        # Process input and generate logits\n",
    "        inputs = self.processor(speech, sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(inputs.input_values).logits\n",
    "\n",
    "        # Decode the logits into phonemes and return\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        phonemes = self.processor.batch_decode(predicted_ids)[0]\n",
    "        \n",
    "        return phonemes\n",
    "    \n",
    "    def text2phonemes(self, text):\n",
    "        \"\"\"Converts text into IPA phonemes using eSpeak-NG\"\"\"\n",
    "        phonemes = phonemize(text, language='en-us').replace(' ', '')\n",
    "        return phonemes\n",
    "    \n",
    "    def get_misalignments(self, user_phonemes, target_phonemes):\n",
    "        \"\"\"Evaluates alignment between two phoneme sequences\"\"\"\n",
    "        # Get the Levenshtein alignment codes\n",
    "        opcodes = lev.opcodes(target_phonemes, user_phonemes)\n",
    "        # Compute a percentage similarity based on Levenshtein distance\n",
    "        distance = lev.distance(target_phonemes, user_phonemes)\n",
    "        similarity = round(distance/max(len(user_phonemes), len(target_phonemes))*100, 2)\n",
    "\n",
    "        matches = []\n",
    "        substitutions = []\n",
    "        deletions = []\n",
    "        insertions = []\n",
    "                \n",
    "        # Extract matches and various kinds of errors\n",
    "        for op, ref_start, ref_end, user_start, user_end in opcodes:\n",
    "            # Encode as reference indices and attempt indices\n",
    "            indices = ((ref_start, ref_end), (user_start, user_end))\n",
    "\n",
    "            if op == 'equal':\n",
    "                matches.append(indices)\n",
    "            elif op == 'replace':\n",
    "                substitutions.append(indices)\n",
    "            elif op == 'delete':\n",
    "                deletions.append(indices)\n",
    "            elif op == 'insert':\n",
    "                insertions.append(indices)\n",
    "\n",
    "        return similarity, matches, substitutions, deletions, insertions\n",
    "    \n",
    "    def get_viseme(self, phoneme):\n",
    "        \"\"\"Returns a viseme and a description for a phoneme\"\"\"\n",
    "\n",
    "    def get_feedback(self, phoneme):\n",
    "        \"\"\"Returns the corresponding feedback to help understand a phoneme\"\"\"\n",
    "    \n",
    "    def __call__(self):\n",
    "        \"\"\"Makes the whole pipeline run from start to finish\"\"\"\n",
    "        # Step 1. Get the user's phonemes and the reference phonemes\n",
    "        user_phonemes = self.speech2phonemes('some_arbitrary_audio_path.wav')\n",
    "        target_phonemes = self.text2phonemes('some_reference_speech')\n",
    "\n",
    "        # Step 2. Get similarity misalignment indices between attempt and target\n",
    "        similarity, matches, substitutions, deletions, insertions = self.get_misalignments(user_phonemes, target_phonemes)\n",
    "\n",
    "        return similarity, matches, substitutions, deletions, insertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bae688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from phonemizer.separator import Separator\n",
    "from phonemizer import phonemize\n",
    "import os\n",
    "\n",
    "# Specific for my implementation on my personal computer\n",
    "os.environ['PHONEMIZER_ESPEAK_LIBRARY'] = 'C:/Program Files/eSpeak NG/libespeak-ng.dll'\n",
    "\n",
    "def text2phonemes(text):\n",
    "    \"\"\"Converts text into IPA phonemes and returns a structured list.\"\"\"\n",
    "    # Define separators: a space between phonemes, and '|' between words.\n",
    "    separator = Separator(phone=' ', word='|', syllable='')\n",
    "    \n",
    "    # Phonemize the text\n",
    "    phonemized_text = phonemize(\n",
    "        text,\n",
    "        language='en-us',\n",
    "        backend='espeak',\n",
    "        separator=separator,\n",
    "        strip=True,\n",
    "        preserve_punctuation=False\n",
    "    )\n",
    "    \n",
    "    # Split into words and then into phonemes\n",
    "    phonemized_words = phonemized_text.split('|')\n",
    "    original_words = text.split(\" \")\n",
    "\n",
    "    # Map phonemes to characters\n",
    "    for p_word, o_word in zip(phonemized_words, original_words):\n",
    "        mapping_length = len(o_word)/len(p_word)\n",
    "        mapping_characters = ()\n",
    "\n",
    "\n",
    "    phoneme_list = [word.split() for word in words]\n",
    "\n",
    "    phoneme_mapping = []\n",
    "\n",
    "    for phonemized_word, text_word in zip(words, text.split(\" \")):\n",
    "\n",
    "    for word in words:\n",
    "        phonemes = word.split()\n",
    "        mapping_length = len(word)/len()\n",
    "    \n",
    "    \n",
    "    return phoneme_list, \"\".join(words).replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5590dae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['æ', 'n', 'θ', 'ə', 'n', 'i'],\n",
       "  ['l', 'aɪ', 'k', 's'],\n",
       "  ['t', 'ʊ'],\n",
       "  ['iː', 't'],\n",
       "  ['æ', 'p', 'əl'],\n",
       "  ['p', 'aɪ']],\n",
       " 'ænθənilaɪkstʊiːtæpəlpaɪ')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2phonemes('Anthony likes to eat apple pie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73061f82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
