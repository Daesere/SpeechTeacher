{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cfbffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "equal (reference: 0, 3) (attempt: 0, 3)\n",
      "delete (reference: 3, 4) (attempt: 3, 3)\n",
      "equal (reference: 4, 5) (attempt: 3, 4)\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2Tokenizer,Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "from phonemizer import phonemize\n",
    "import Levenshtein as lev\n",
    "import librosa\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Specific for my local implementation\n",
    "os.environ['PHONEMIZER_ESPEAK_LIBRARY'] = 'C:/Program Files/eSpeak NG/libespeak-ng.dll'\n",
    "\n",
    "phoneme_visemes = {\n",
    "    'phoneme': ('viseme_id', 'instructions')\n",
    "}\n",
    "\n",
    "class Pipeline():\n",
    "    \"\"\"\n",
    "    Evaluates speech and returns feedback to\n",
    "    target pronunciation points that require further work.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.model_name = \"facebook/wav2vec2-lv-60-espeak-cv-ft\"\n",
    "        self.feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(self.model_name)\n",
    "        self.tokenizer = Wav2Vec2Tokenizer.from_pretrained(self.model_name)\n",
    "        self.processor = Wav2Vec2Processor.from_pretrained(self.model_name, feature_extractor=self.feature_extractor, tokenizer=self.tokenizer)\n",
    "        self.model = Wav2Vec2ForCTC.from_pretrained(self.model_name)\n",
    "\n",
    "    def speech2phonemes(self, audio_path):\n",
    "        \"\"\"Transforms user audio into IPA phonemes for evaluation\"\"\"\n",
    "        # Load and normalize the user's audio\n",
    "        speech, sr = librosa.load(audio_path, sr=16_000, mono=True)\n",
    "        speech = librosa.util.normalize(speech)\n",
    "\n",
    "        # Process input and generate logits\n",
    "        inputs = self.processor(speech, sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(inputs.input_values).logits\n",
    "\n",
    "        # Decode the logits into phonemes and return\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        phonemes = self.processor.batch_decode(predicted_ids)[0]\n",
    "        \n",
    "        return phonemes\n",
    "    \n",
    "    def text2phonemes(self, text):\n",
    "        \"\"\"Converts text into IPA phonemes using eSpeak-NG\"\"\"\n",
    "        phonemes = phonemize(text, language='en-us').replace(' ', '')\n",
    "        return phonemes\n",
    "    \n",
    "    def get_misalignments(self, user_phonemes, target_phonemes):\n",
    "        \"\"\"Evaluates alignment between two phoneme sequences\"\"\"\n",
    "        # Get the Levenshtein alignment codes\n",
    "        opcodes = lev.opcodes(target_phonemes, user_phonemes)\n",
    "        # Compute a percentage similarity based on Levenshtein distance\n",
    "        distance = lev.distance(target_phonemes, user_phonemes)\n",
    "        similarity = round(distance/max(len(user_phonemes), len(target_phonemes))*100, 2)\n",
    "\n",
    "        matches = []\n",
    "        substitutions = []\n",
    "        deletions = []\n",
    "        insertions = []\n",
    "                \n",
    "        # Extract matches and various kinds of errors\n",
    "        for op, ref_start, ref_end, user_start, user_end in opcodes:\n",
    "            # Encode as reference indices and attempt indices\n",
    "            indices = ((ref_start, ref_end), (user_start, user_end))\n",
    "\n",
    "            if op == 'equal':\n",
    "                matches.append(indices)\n",
    "            elif op == 'replace':\n",
    "                substitutions.append(indices)\n",
    "            elif op == 'delete':\n",
    "                deletions.append(indices)\n",
    "            elif op == 'insert':\n",
    "                insertions.append(indices)\n",
    "\n",
    "        return similarity, matches, substitutions, deletions, insertions\n",
    "    \n",
    "    def get_accuracy(self, target_phonemes, misalignments):\n",
    "        \"\"\"Returns a number based on sequence identity\"\"\"\n",
    "        \n",
    "    def get_viseme(self, phoneme):\n",
    "        \"\"\"Returns a viseme and a description for a phoneme\"\"\"\n",
    "\n",
    "    def get_feedback(self, phoneme):\n",
    "        \"\"\"Returns the corresponding feedback to help understand a phoneme\"\"\"\n",
    "        \n",
    "    \n",
    "    def __call__(self):\n",
    "        \"\"\"Makes the whole pipeline run from start to finish\"\"\"\n",
    "        # Step 1. Get the user's phonemes and the reference phonemes\n",
    "        user_phonemes = self.speech2phonemes('some_arbitrary_audio_path.wav')\n",
    "        target_phonemes = self.text2phonemes('some_reference_speech')\n",
    "\n",
    "        # Step 2. Get similarity misalignment indices between attempt and target\n",
    "        similarity, matches, substitutions, deletions, insertions = self.get_misalignments(user_phonemes, target_phonemes)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0d2e8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\mais-hackathon\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Wav2Vec2PhonemeCTCTokenizer'. \n",
      "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
      "d:\\Projects\\mais-hackathon\\venv\\Lib\\site-packages\\transformers\\models\\wav2vec2\\tokenization_wav2vec2.py:720: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2Tokenizer,Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "import torch\n",
    "\n",
    "model_name = \"facebook/wav2vec2-lv-60-espeak-cv-ft\"\n",
    "\n",
    "# Load the tokenizer and the feature extractor\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name)\n",
    "tokenizer = Wav2Vec2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load the processor and the model\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_name, feature_extractor=feature_extractor, tokenizer=tokenizer)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be2cad6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "# Load audio with 16kHz sampling rate\n",
    "audio_path = \"harvard.wav\"\n",
    "speech, sr = librosa.load(audio_path, sr=16000, mono=True)\n",
    "\n",
    "# Normalize audio (optional but recommended)\n",
    "import numpy as np\n",
    "speech = librosa.util.normalize(speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4279df20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the audio\n",
    "inputs = processor(speech, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "# Run inference\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs.input_values).logits\n",
    "\n",
    "# Get predicted phonemes\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "phonemes = processor.batch_decode(predicted_ids)\n",
    "\n",
    "# Output the phoneme string\n",
    "ipa_string = phonemes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b404a27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ðəsteɪlsmɛlʌvoʊldbiːlɪŋɡɚzɪtteɪkshiːttəbɹɪŋaʊtðɪoʊdɚɐkoʊlddɪpɹɪstoːɹzhɛlθændzɛsteɪsaʊltpɪkəlteɪstfaɪnwɪðheɪmtækəlzɑːlpæstɔːɹɹɑːɹmaɪfeɪvɹəteɪzɛstfəlfuːdɪzðɪhɑːtkɹɑːsbʌn'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipa_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dd66dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:11: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\dante\\AppData\\Local\\Temp\\ipykernel_8324\\356227992.py:11: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  os.environ['PHONEMIZER_ESPEAK_LIBRARY'] = 'C:\\Program Files\\eSpeak NG\\libespeak-ng.dll'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðəsteɪlsmɛlʌvoʊldbɪɹlɪŋɡɚzɪtteɪkshiːttəbɹɪŋaʊtðɪoʊdɚɹɐkoʊlddɪpɹᵻstɔːɹzhɛlθændzɛstɐsɔltpɪkəlteɪstsfaɪnwɪðhæmtɑːkoʊzælpæstɚɹɑːɹmaɪfeɪvɚɹᵻtɐzɛstfəlfuːdɪzðəhɑːtkɹɔsbʌn\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from phonemizer import phonemize\n",
    "from phonemizer.separator import Separator\n",
    "\n",
    "# Define separators for phones, words, and syllables (optional, defaults are fine)\n",
    "# By default, phones are separated by a space and words by a space\n",
    "# The default output format with espeak-ng is IPA.\n",
    "\n",
    "text = \"the stale smell of old beer lingers it takes heat to bring out the odor a cold dip restores health and zest a salt pickle tastes fine with ham tacos al pastor are my favorite a zestful food is the hot cross bun\"\n",
    "\n",
    "os.environ['PHONEMIZER_ESPEAK_LIBRARY'] = 'C:\\Program Files\\eSpeak NG\\libespeak-ng.dll'\n",
    "\n",
    "# Simplest use case:\n",
    "phonemized_text = phonemize(text, language='en-us').replace(' ', '')\n",
    "\n",
    "print(phonemized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7c34125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\dante\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2b1fdab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.edit_distance(ipa_string, phonemized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a133199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match: ['ˈh', 'ɛ', 'l']\n",
      "Deletion: Ref(['a']) was missing\n",
      "Match: ['oʊ']\n"
     ]
    }
   ],
   "source": [
    "import Levenshtein as lev\n",
    "\n",
    "reference = [\"ˈh\", \"ɛ\", \"l\", \"a\", \"oʊ\"]\n",
    "attempt = [\"ˈh\", \"ɛ\", \"l\", \"oʊ\"]\n",
    "\n",
    "# Get the optimal alignment strings\n",
    "opcodes = lev.opcodes(reference, attempt)\n",
    "distance = lev.distance(reference, attempt)\n",
    "\n",
    "for op, ref_start, ref_end, att_start, att_end in opcodes:\n",
    "    if op == 'equal':\n",
    "        print(f\"Match: {reference[ref_start:ref_end]}\")\n",
    "    elif op == 'replace':\n",
    "        print(f\"Substitution: Ref({reference[ref_start:ref_end]}) -> Usr({attempt[att_start:att_end]})\")\n",
    "    elif op == 'delete':\n",
    "        print(f\"Deletion: Ref({reference[ref_start:ref_end]}) was missing\")\n",
    "    elif op == 'insert':\n",
    "        print(f\"Insertion: Usr({attempt[att_start:att_end]}) was extra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bff3868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
